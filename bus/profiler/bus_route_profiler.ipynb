{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c9c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "outdir = './output'\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "with open('bus_routes.json', 'r') as f:\n",
    "  data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = \"851\"\n",
    "direction = \"1\"\n",
    "route = data[service][direction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250bb32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "od = []\n",
    "for seq, id in enumerate(route[:-1]):\n",
    "    next_stop = seq + 1\n",
    "    for stop in route[next_stop:]:\n",
    "        if id['code'] == stop['code']:\n",
    "            break #we've come back to the same bus stop. assume all pax from here on out boarded on 2nd visit.\n",
    "        od.append((int(id['code']), int(stop['code'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e72456",
   "metadata": {},
   "source": [
    "To use:\n",
    "Copy origin_destination_summary from the data folders into the working directory, rename to \"od.csv\" or change filename below\n",
    "\n",
    "This code also works with byhour files but requires manual fixing:\n",
    "- Remove line 1 (it just says `TOTAL_TRIPS` which is useless to us)\n",
    "- Replace this part of line 2 `TIME_PER_HOUR,,,0,1` with `ORIGIN_PT_CODE,DESTINATION_PT_CODE,DAY_TYPE,0,1`\n",
    "- Delete line 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f53a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_source = pd.read_csv(\"1d-od.csv\")\n",
    "#df_source = pd.read_csv(\"od.csv\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40866ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for src, dest in od:\n",
    "    df = pd.concat([df, df_source[(df_source['ORIGIN_PT_CODE'] == src) & (df_source['DESTINATION_PT_CODE'] == dest)]])\n",
    "\n",
    "#retrieve the filtered report for the given service and direction\n",
    "df.to_csv(f\"output/{service}_{direction}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f166bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wd = df[df[\"DAY_TYPE\"] == \"WEEKDAY\"]\n",
    "pd.pivot_table(df, index=\"ORIGIN_PT_CODE\", columns=\"DESTINATION_PT_CODE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# we keep only the first digit of the stop code as it generally conforms to geographical areas.\n",
    "# second digit may also be useful in some cases but could create too much statistical noise.\n",
    "# for example, both CCK and BP have a mix of stop codes in both 44000 and 45000 ranges\n",
    "def rounder(x):\n",
    "    return int(math.floor(x/1000)) * 1000\n",
    "\n",
    "df_round = df\n",
    "df_round.ORIGIN_PT_CODE = df_round.ORIGIN_PT_CODE.apply(rounder)\n",
    "df_round.DESTINATION_PT_CODE = df_round.DESTINATION_PT_CODE.apply(rounder)\n",
    "df_round = df_round.groupby([\"DAY_TYPE\", \"ORIGIN_PT_CODE\", \"DESTINATION_PT_CODE\"]).sum()\n",
    "df_round.to_csv(f\"output/{service}_{direction}_grouped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321cf4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981f23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"190_1_time.csv\", \"190_2_time.csv\", \"972_1_time.csv\", \"960_1_time.csv\",\"960_2_time.csv\"]\n",
    "df_cons = pd.DataFrame()\n",
    "for fn in files:\n",
    "    df_cons = pd.concat([df_cons, pd.read_csv(f\"output/{fn}\")])\n",
    "df_cons = df_cons.drop_duplicates()\n",
    "df_cons.to_csv(\"btl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7cd775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounder(x):\n",
    "    return int(math.floor(x/1000)) * 1000\n",
    "\n",
    "df_round = df_cons\n",
    "df_round.ORIGIN_PT_CODE = df_round.ORIGIN_PT_CODE.apply(rounder)\n",
    "df_round.DESTINATION_PT_CODE = df_round.DESTINATION_PT_CODE.apply(rounder)\n",
    "df_round = df_round.groupby([\"DAY_TYPE\", \"ORIGIN_PT_CODE\", \"DESTINATION_PT_CODE\"]).sum()\n",
    "df_round.to_csv(f\"btl_grouped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb75e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
